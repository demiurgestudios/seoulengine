#!/usr/bin/env python

"""
This script reads in the Unicode data files and generates optimized case mapping
data for the Seoul Engine in order to implement proper Unicode-aware versions
of String::ToUpper() and String::ToLower().
"""

import collections
import os
import re
import sys

AUTOGEN_BASENAME = 'CaseMappingData.cpp'
AUTOGEN_HEADER = \
r"""// -*- fundamental -*-
/**
 * \file %s
 * \brief String implementation for Seoul
 *
 * Copyright (c) Demiurge Studios, Inc.
 * 
 * This source code is licensed under the MIT license.
 * Full license details can be found in the LICENSE file
 * in the root directory of this source tree.
 */

///////////////////////////////////////////////////////////////////////////////
// WARNING: DO NOT MODIFY THIS FILE!                                         //
//                                                                           //
// This file is autogenerated by gen_unicode_case_mapping.py to generate     //
// Unicode case mapping data for use in String::ToUpper() and                //
// String::ToLower().  If you modify this file, your modifications WILL BE   //
// LOST the next time that script is run.  Modify the script instead.        //
///////////////////////////////////////////////////////////////////////////////

// See the comments CaseMappingData.h for a description of these data
// structures
#include "CaseMappingData.h"

namespace Seoul
{

namespace CaseMappingInternal
{

#define NONE 65535  // Sentinel index indicating no child node

""" % AUTOGEN_BASENAME

AUTOGEN_FOOTER = \
"""
#undef NONE

}  // namespace CaseMappingInternal

} // namespace Seoul
"""

# Mapping from condition names to priority, for the purposes of sorting case
# mappings for the same character with different conditions
CONDITION_PRIORITY = {
    'lt': 0,
    'tr': 1,
    'az': 2,
    'Final_Sigma': 3,
    'After_Soft_Dotted': 4,
    'After_I': 5,
    'More_Above': 6,
    'Not_Before_Dot': 7
}

# Mapping from condition name to C++ flag name
CONDITION_FLAG_MAP = {
    'lt': 'kFlagLithuanian',
    'tr': 'kFlagTurkishAzeri',
    'az': 'kFlagTurkishAzeri',
    'Final_Sigma': 'kFlagFinalSigma',
    'After_Soft_Dotted': 'kFlagAfterSoftDotted',
    'After_I': 'kFlagAfterI',
    'More_Above': 'kFlagMoreAbove',
    'Not_Before_Dot': 'kFlagNotBeforeDot'
}

def condition_sort_key(entry):
    return [CONDITION_PRIORITY[cond] for cond in entry[0]] + [99]

uppercase_map = collections.defaultdict(list)
lowercase_map = collections.defaultdict(list)
# TODO: Title case

def usage():
    print >>sys.stderr, 'Usage: %s path/to/UnicodeData.txt path/to/SpecialCasing.txt' % sys.argv[0]
    sys.exit(1)

def load_unicode_data(f):
    """
    Loads the Unicode case mapping data from the given UnicodeData.txt file
    object
    """

    # Read each line of UnicodeData.txt
    for line in f:
        # Strip comments and separate out into fields
        line = re.sub('#.*', '', line)
        fields = line.split(';')

        # Ignore empty lines
        if len(fields) < 2:
            continue

        codepoint = fields[0]
        simple_uppercase = fields[12]
        simple_lowercase = fields[13]

        # If the character has a simple (1-character) uppercase or lowercase
        # mapping, store that
        if simple_uppercase:
            uppercase_map[int(codepoint, 16)].append(((), [int(simple_uppercase, 16)]))
        if simple_lowercase:
            lowercase_map[int(codepoint, 16)].append(((), [int(simple_lowercase, 16)]))

def load_special_casing(f):
    """
    Loads the Unicode special casing data from the given SpecialCasing.txt file
    object
    """

    # Read each line of SpecialCasing.txt
    for line in f:
        # Strip comments and separate out into fields
        line = re.sub('#.*', '', line)
        fields = line.split(';')

        # Ignore empty lines
        if len(fields) < 2:
            continue

        codepoint_str = fields[0].strip()
        lowercase = fields[1].strip()
        uppercase = fields[3].strip()
        conditions = fields[4].strip()

        # Store the character mapping along with it scondition flags.  The
        # mapping might be more than one character long.
        codepoint = int(codepoint_str, 16)
        if uppercase != codepoint_str:
            uppercase_map[codepoint].append((conditions.split(), [int(x, 16) for x in uppercase.split()]))
        if lowercase != codepoint_str:
            lowercase_map[codepoint].append((conditions.split(), [int(x, 16) for x in lowercase.split()]))

class CharEntry(object):
    def __init__(self, codepoint, s, flags):
        self.codepoint = codepoint
        self.idx = -1
        self.s = s
        self.offset = -1
        self.flags = flags

    def __str__(self):
        return '<CharEntry: codepoint=%s idx=%d s=%r offset=%d flags=%s>' % (self.codepoint, self.idx, self.s, self.offset, self.flags)


class TableNode(object):
    def __init__(self, n):
        self.children = [None] * n
        self.idx = -1

    def insert(self, idx, bits, depth, entry):
        # Inserts a CharEntry into this subtree
        if depth > 0:
            if not self.children[idx]:
                self.children[idx] = TableNode(64)
                self.children[idx].idx = idx

            next_idx = (bits >> (6*(depth-1))) & 0x3F
            self.children[idx].insert(next_idx, bits, depth - 1, entry)
        else:
            if not self.children[idx]:
                self.children[idx] = []
            self.children[idx].append(entry)

    def __str__(self):
        otherattrs = ''
        if self.hasattr('strings') and self.hasattr('entries'):
            otherattrs = ' strings=%r entries=%s' % (self.strings, self.entries)
        return '<TableNode: idx=%d children=%s%s>' % (self.idx, self.children, otherattrs)

def utf8_encode_char(codepoint):
    """Encodes a single code point in UTF-8"""

    if codepoint < 0x10000:
        return unichr(codepoint).encode('UTF-8')
    else:
        # unichr() can't deal with code points above 0x10000
        return chr(0xF0 | (codepoint >> 18)) + \
               chr(0x80 | ((codepoint >> 12) & 0x3F)) + \
               chr(0x80 | ((codepoint >> 6) & 0x3F)) + \
               chr(0x80 | (codepoint & 0x3F))

def utf8_encode(codepoints):
    """Encodes a list of code points in UTF-8"""
    return ''.join(utf8_encode_char(c) for c in codepoints)

def set_node_indices(root, node):
    """Sets each child node's unique index"""

    # Traverse the tree in depth-first order
    for child in node.children:
        if isinstance(child, TableNode):
            child.idx = len(root.all_children)
            root.all_children.append(child)
            set_node_indices(root, child)

def make_table(case_map):
    """
    Converts the given case mapping data the Seoul engine's case conversion
    table structure
    """

    root = TableNode(256)
    root.strings = ''
    root.entries = []

    for codepoint in case_map:
        # Convert each raw entry into a CharEntry instance
        raw_entries = sorted(case_map[codepoint], key=condition_sort_key)
        for raw_entry in raw_entries:
            flags = raw_entry[0]
            flags = [CONDITION_FLAG_MAP[flag] for flag in flags]
            s = utf8_encode(raw_entry[1])
            entry = CharEntry(codepoint=codepoint, s=s, flags=flags)
            root.entries.append(entry)

    root.entries.sort(key=lambda x:x.codepoint)

    # Insert all of the entries into the table in order
    for i, entry in enumerate(root.entries):
        codepoint = entry.codepoint
        entry.idx = i

        # Set a bit indicating if this entry has more entries after it for
        # the same code point
        if i < len(root.entries) - 1 and root.entries[i + 1].codepoint == codepoint:
            entry.flags.append('kFlagMoreEntries')

        # Encode the code point into UTF-8 and insert it into the table
        if codepoint < 0x0080:
            root.insert(codepoint, 0, 0, entry)
        elif codepoint < 0x0800:
            root.insert(0xC0 + (codepoint >> 6), codepoint & 0x3F, 1, entry)
        elif codepoint < 0x10000:
            root.insert(0xE0 + (codepoint >> 12), codepoint & 0xFFF, 2, entry)
        else:
            assert codepoint < 0x110000
            root.insert(0xF0 + (codepoint >> 18), codepoint & 0x3FFFF, 3, entry)

        # Add the entry's string to the string pool
        entry.offset = len(root.strings)
        root.strings += entry.s

    root.all_children = []
    set_node_indices(root, root)

    return root

def write_case_mapping(f):
    """
    Writes out the case mapping data to the given C++ source code for the Seoul
    Engine
    """

    f.write(AUTOGEN_HEADER)
    write_case_mapping_table(f, make_table(uppercase_map), 'Upper')
    write_case_mapping_table(f, make_table(lowercase_map), 'Lower')
    f.write(AUTOGEN_FOOTER)

def chunks(l, n):
    """Yields successive n-sized chunks from the given list"""
    for i in range(0, len(l), n):
        yield l[i:i+n]

def write_case_mapping_table(f, table, name):
    """
    Writes out the given case mapping table to the given file stream
    """

    f.write("/////////////////////////// BEGIN %sCASE DATA ///////////////////////////\n\n" % name.upper())
    f.write("static const CharEntry ka%sEntries[] =\n{\n" % name)
    for i, entry in enumerate(table.entries):
        flags = ' | '.join(entry.flags) if entry.flags else '0'
        f.write('\t{%4d, %d, %s},  // %d, U+%04X\n' % (entry.offset, len(entry.s), flags, i, entry.codepoint))
    f.write("};\n\n")

    f.write("static const SubTable ka%sSubTables[] =\n{\n" % name)
    for i, node in enumerate(table.all_children):
        child_strs = []
        for child in node.children:
            if isinstance(child, list):
                child_strs.append('%4d' % (child[0].idx,))
            elif isinstance(child, TableNode):
                child_strs.append('%4d' % (child.idx,))
            else:
                child_strs.append('NONE')

        lines = ['\t\t%s,\n' % ', '.join(chunk) for chunk in chunks(child_strs, 8)]

        f.write("\t{ {  // %d\n%s\t} },\n" % (i, ''.join(lines)))

    f.write("};\n\n")

    f.write("static const UByte ka%sStringPool[] =\n{\n" % name)
    string_data = ['%3d' % ord(c) for c in table.strings]
    f.write(''.join('\t%s,\n' % ','.join(chunk) for chunk in chunks(string_data, 16)))
    f.write("};\n\n")

    f.write("const RootTable g_%scaseTable =\n{\n" % name)
    f.write("\tka%sEntries,\n" % name)
    f.write("\tka%sSubTables,\n\n" % name)

    f.write("\t// m_apBaseEntries\n\t{\n")
    for i, child in enumerate(table.children[:128]):
        if child:
            child_str = "&ka%sEntries[%d]" % (name, child[0].idx)
        else:
            child_str = "NULL"
        f.write("\t\t%s,  // %d\n" % (child_str, i))
    f.write("\t},\n\n")

    f.write("\t// m_apSubTables\n\t{\n")
    for i, child in enumerate(table.children[192:248]):
        if child:
            child_str = "&ka%sSubTables[%d]" % (name, child.idx)
        else:
            child_str = "NULL"
        f.write("\t\t%s,  // %d\n" % (child_str, i))
    f.write("\t},\n\n")

    f.write("\t(const Byte *)ka%sStringPool\n" % name)
    f.write("};\n\n")
    f.write("//////////////////////////// END %sCASE DATA ////////////////////////////\n\n" % name.upper())

def main():
    if len(sys.argv) < 3:
        usage()

    # Load the Unicode data files.  Load SpecialCasing.txt first so that if
    # there are any unconditional mappings (such as U+0130 in
    # non-Turkish/Azeri), those mappings get preferred over the simple mappings
    # in UnicodeData.txt
    with open(sys.argv[2], 'r') as f:
        print 'Loading %s...' % sys.argv[2]
        load_special_casing(f)

    with open(sys.argv[1], 'r') as f:
        print 'Loading %s...' % sys.argv[1]
        load_unicode_data(f)

    # Write out the case mapping data
    outfilename = os.path.normpath(
        os.path.join(os.path.dirname(__file__),
                     '../Dev/SeoulEngine/Code/Core',
                     AUTOGEN_BASENAME))

    print 'Writing %s...' % outfilename
    with open(outfilename, 'w') as f:
        write_case_mapping(f)

if __name__ == '__main__':
    main()
